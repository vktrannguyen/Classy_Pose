{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f6763cc",
   "metadata": {},
   "source": [
    "# Classification models for pose prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f482d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import oddt\n",
    "import oddt.pandas as opd\n",
    "from oddt.pandas import ChemDataFrame\n",
    "from oddt.fingerprints import PLEC\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_curve, accuracy_score, auc\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import parallel_backend\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import tempfile\n",
    "import hyperopt\n",
    "from hyperopt import hp, tpe, Trials, fmin, STATUS_OK, space_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad2ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load csv files containing training and test data\n",
    "\n",
    "train_data = pd.read_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/data_partitions/training_1/RMSD/training_data_poses.csv\")\n",
    "Train_Class = train_data['Classification']\n",
    "test_data = pd.read_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/hard_test/RMSD/hard_test_data_poses.csv\")\n",
    "Test_Class = test_data['Classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584ab33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load PLEC fingerprints of training and test data\n",
    "\n",
    "d_train_csv = pd.read_csv('/home/vktrannguyen/Projects/redocked/PLEC/data_partitions/training_1/PLEC/training_data_PLEC.csv', header=None)\n",
    "d_test_csv = pd.read_csv('/home/vktrannguyen/Projects/redocked/PLEC/hard_test/PLEC/hard_test_data_PLEC.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad3d05c",
   "metadata": {},
   "source": [
    "## RF models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4c5012",
   "metadata": {},
   "source": [
    "#### Without hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "839e7962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the RF model on the training molecules:\n",
    "rf_plec = RandomForestClassifier(n_estimators = 400, max_features = 'sqrt', n_jobs = 30)\n",
    "rf_plec.fit(d_train_csv, Train_Class)\n",
    "\n",
    "#Test the RF model on the test molecules:\n",
    "prediction_test_rf_plec_class = rf_plec.predict(d_test_csv)\n",
    "prediction_test_rf_plec_prob = rf_plec.predict_proba(d_test_csv)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_rf = pd.DataFrame({\"Good_Pose_Prob\": prediction_test_rf_plec_prob[:, 1],\n",
    "                               \"Predicted_Class\": prediction_test_rf_plec_class,\n",
    "                               \"Real_Class\": Test_Class})\n",
    "\n",
    "rmsd = test_data.iloc[:, 1]\n",
    "pose = test_data.iloc[:, 0]\n",
    "\n",
    "plec_result_rf['RMSD'] = rmsd\n",
    "plec_result_rf['Pose'] = pose\n",
    "\n",
    "plec_result_rf.to_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/hard_test/results/RF/RF_no-tuning_05.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef639f15",
   "metadata": {},
   "source": [
    "#### With hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17bc18c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:18<00:00,  1.88s/trial, best loss: 0.7778339991353744]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"n_estimators\": hp.choice(\"n_estimators\", np.arange(100, 500, 5000)),\n",
    "         \"max_depth\": hp.choice(\"max_depth\", [1, 2, 3, 4, 5]),\n",
    "         \"criterion\": hp.choice(\"criterion\", ['gini', 'entropy'])}\n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_randomforest(space):\n",
    "    model = RandomForestClassifier(n_estimators = int(space['n_estimators']),\n",
    "                                   max_depth = int(space['max_depth']),\n",
    "                                   criterion = space['criterion'], n_jobs = 40)\n",
    "    model.fit(np.array(d_train_csv), Train_Class)\n",
    "    predicted_train = model.predict(np.array(d_train_csv))\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_rf_classification = fmin(fn = hyperparameter_tuning_randomforest, space = space, algo = tpe.suggest,\n",
    "                              max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_rf_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492d0c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the RF model on the training molecules, using optimal parameters:\n",
    "rf_plec = RandomForestClassifier(n_estimators = best_params['n_estimators'], \n",
    "                                 max_depth = best_params['max_depth'], \n",
    "                                 criterion = best_params['criterion'],\n",
    "                                 max_features = 'sqrt', n_jobs = 30)\n",
    "rf_plec.fit(d_train_csv, Train_Class)\n",
    "\n",
    "#Test the RF model on the test molecules:\n",
    "prediction_test_rf_plec_class = rf_plec.predict(d_test_csv)\n",
    "prediction_test_rf_plec_prob = rf_plec.predict_proba(d_test_csv)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_rf = pd.DataFrame({\"Good_Pose_Prob\": prediction_test_rf_plec_prob[:, 1],\n",
    "                               \"Predicted_Class\": prediction_test_rf_plec_class,\n",
    "                               \"Real_Class\": Test_Class})\n",
    "\n",
    "rmsd = test_data.iloc[:, 1]\n",
    "pose = test_data.iloc[:, 0]\n",
    "\n",
    "plec_result_rf['RMSD'] = rmsd\n",
    "plec_result_rf['Pose'] = pose\n",
    "\n",
    "plec_result_rf.to_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/data_partitions/results_1/RF/RF_tuning_05.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cc35d0",
   "metadata": {},
   "source": [
    "## XGB models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ba3c6",
   "metadata": {},
   "source": [
    "#### Without hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c516ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:43:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117766796/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#Train the XGB model on the training molecules:\n",
    "xgb_plec = XGBClassifier(n_jobs = 40)\n",
    "xgb_plec.fit(np.array(d_train_csv), Train_Class)\n",
    "\n",
    "#Test the XGB model on the test molecules:\n",
    "prediction_test_xgb_plec_class = xgb_plec.predict(np.array(d_test_csv))\n",
    "prediction_test_xgb_plec_prob = xgb_plec.predict_proba(np.array(d_test_csv))\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_xgb = pd.DataFrame({\"Good_Pose_Prob\": prediction_test_xgb_plec_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_xgb_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "\n",
    "rmsd = test_data.iloc[:, 1]\n",
    "pose = test_data.iloc[:, 0]\n",
    "\n",
    "plec_result_xgb['RMSD'] = rmsd\n",
    "plec_result_xgb['Pose'] = pose\n",
    "\n",
    "plec_result_xgb.to_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/hard_test/results/XGB/XGB_no-tuning_05.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92e6d5f",
   "metadata": {},
   "source": [
    "#### With hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "248fb41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vktrannguyen/anaconda3/envs/code-env/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117766796/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 10%|████████████▋                                                                                                                  | 1/10 [07:01<1:03:16, 421.83s/trial, best loss: 0.00019305715655837385]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vktrannguyen/anaconda3/envs/code-env/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:20:34] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117766796/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 20%|█████████████████████████▍                                                                                                     | 2/10 [17:55<1:14:27, 558.43s/trial, best loss: 0.00019305715655837385]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vktrannguyen/anaconda3/envs/code-env/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:31:28] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117766796/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 30%|██████████████████████████████████████                                                                                         | 3/10 [30:44<1:16:21, 654.51s/trial, best loss: 0.00019305715655837385]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vktrannguyen/anaconda3/envs/code-env/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:44:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117766796/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 40%|███████████████████████████████████████████████████▌                                                                             | 4/10 [38:25<57:47, 577.98s/trial, best loss: 0.00019305715655837385]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vktrannguyen/anaconda3/envs/code-env/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:51:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117766796/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|████████████████████████████████████████████████████████████████▌                                                                | 5/10 [48:05<48:12, 578.57s/trial, best loss: 0.00019305715655837385]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vktrannguyen/anaconda3/envs/code-env/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:01:38] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117766796/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 60%|████████████████████████████████████████████████████████████████████████████▏                                                  | 6/10 [1:01:36<43:51, 657.89s/trial, best loss: 0.00019305715655837385]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vktrannguyen/anaconda3/envs/code-env/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:15:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117766796/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 70%|████████████████████████████████████████████████████████████████████████████████████████▉                                      | 7/10 [1:12:26<32:45, 655.30s/trial, best loss: 0.00019305715655837385]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vktrannguyen/anaconda3/envs/code-env/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:25:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117766796/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 8/10 [1:23:19<21:48, 654.36s/trial, best loss: 0.00019305715655837385]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vktrannguyen/anaconda3/envs/code-env/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:36:52] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117766796/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 9/10 [1:38:26<12:13, 733.53s/trial, best loss: 0.00019305715655837385]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vktrannguyen/anaconda3/envs/code-env/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:51:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117766796/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [1:47:58<00:00, 647.85s/trial, best loss: 0.00019305715655837385]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'n_estimators': 1778.2134802018963,\n",
       " 'reg_lambda': 0.2640422650249682}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"max_depth\": hp.choice(\"max_depth\", [3, 4, 5, 6, 7, 8, 9, 10, 18]),\n",
    "         \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 1), \n",
    "         \"n_estimators\": hp.uniform(\"n_estimators\", 1000, 5000)} \n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_XGB(space):\n",
    "    model = XGBClassifier(objective = \"binary:logistic\", \n",
    "                          max_depth = space['max_depth'],\n",
    "                          reg_lambda = space['reg_lambda'],\n",
    "                          n_estimators = int(space['n_estimators']))\n",
    "    model.fit(np.array(d_train_csv), Train_Class)\n",
    "    predicted_train = model.predict(np.array(d_train_csv))\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_xgb_classification = fmin(fn = hyperparameter_tuning_XGB, space = space, algo = tpe.suggest, \n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_xgb_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5a61f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:38:30] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117766796/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#Train the XGB model on the training molecules, using optimal parameters:\n",
    "xgb_plec = XGBClassifier(objective = \"binary:logistic\", \n",
    "                         max_depth = best_params['max_depth'], \n",
    "                         reg_lambda = best_params['reg_lambda'], \n",
    "                         n_estimators = int(best_params['n_estimators']),\n",
    "                         n_jobs = 40, random_state = 0)\n",
    "xgb_plec.fit(np.array(d_train_csv), Train_Class)\n",
    "\n",
    "#Test the XGB model on the test molecules:\n",
    "prediction_test_xgb_plec_class = xgb_plec.predict(np.array(d_test_csv))\n",
    "prediction_test_xgb_plec_prob = xgb_plec.predict_proba(np.array(d_test_csv))\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_xgb = pd.DataFrame({\"Good_Pose_Prob\": prediction_test_xgb_plec_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_xgb_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "\n",
    "rmsd = test_data.iloc[:, 1]\n",
    "pose = test_data.iloc[:, 0]\n",
    "\n",
    "plec_result_xgb['RMSD'] = rmsd\n",
    "plec_result_xgb['Pose'] = pose\n",
    "\n",
    "plec_result_xgb.to_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/data_partitions/results_1/XGB/XGB_tuning_05.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72513e95",
   "metadata": {},
   "source": [
    "## SVM models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fcacc6",
   "metadata": {},
   "source": [
    "#### Without hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72ed273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the SVM model on the training molecules:\n",
    "svm_plec = SVC(degree = 3, kernel = \"rbf\", probability = True)\n",
    "svm_plec.fit(d_train_csv, Train_Class)\n",
    "\n",
    "#Test the SVM model on the test molecules:\n",
    "prediction_test_svm_plec_class = svm_plec.predict(d_test_csv)\n",
    "prediction_test_svm_plec_prob = svm_plec.predict_proba(d_test_csv)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_svm  = pd.DataFrame({\"Good_Pose_Prob\": prediction_test_svm_plec_prob[:, 1],\n",
    "                                 \"Predicted_Class\": prediction_test_svm_plec_class,\n",
    "                                 \"Real_Class\": Test_Class})\n",
    "\n",
    "rmsd = test_data.iloc[:, 1]\n",
    "pose = test_data.iloc[:, 0]\n",
    "\n",
    "plec_result_svm['RMSD'] = rmsd\n",
    "plec_result_svm['Pose'] = pose\n",
    "\n",
    "plec_result_svm.to_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/hard_test/results/SVM/SVM_no-tuning_01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "214c9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the SVM model on the training molecules:\n",
    "svm_plec = SVC(degree = 3, kernel = \"rbf\", probability = True)\n",
    "svm_plec.fit(d_train_csv, Train_Class)\n",
    "\n",
    "#Test the SVM model on the test molecules:\n",
    "prediction_test_svm_plec_class = svm_plec.predict(d_test_csv)\n",
    "prediction_test_svm_plec_prob = svm_plec.predict_proba(d_test_csv)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_svm  = pd.DataFrame({\"Good_Pose_Prob\": prediction_test_svm_plec_prob[:, 1],\n",
    "                                 \"Predicted_Class\": prediction_test_svm_plec_class,\n",
    "                                 \"Real_Class\": Test_Class})\n",
    "\n",
    "rmsd = test_data.iloc[:, 1]\n",
    "pose = test_data.iloc[:, 0]\n",
    "\n",
    "plec_result_svm['RMSD'] = rmsd\n",
    "plec_result_svm['Pose'] = pose\n",
    "\n",
    "plec_result_svm.to_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/hard_test/results/SVM/SVM_no-tuning_02.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e56a0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the SVM model on the training molecules:\n",
    "svm_plec = SVC(degree = 3, kernel = \"rbf\", probability = True)\n",
    "svm_plec.fit(d_train_csv, Train_Class)\n",
    "\n",
    "#Test the SVM model on the test molecules:\n",
    "prediction_test_svm_plec_class = svm_plec.predict(d_test_csv)\n",
    "prediction_test_svm_plec_prob = svm_plec.predict_proba(d_test_csv)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_svm  = pd.DataFrame({\"Good_Pose_Prob\": prediction_test_svm_plec_prob[:, 1],\n",
    "                                 \"Predicted_Class\": prediction_test_svm_plec_class,\n",
    "                                 \"Real_Class\": Test_Class})\n",
    "\n",
    "rmsd = test_data.iloc[:, 1]\n",
    "pose = test_data.iloc[:, 0]\n",
    "\n",
    "plec_result_svm['RMSD'] = rmsd\n",
    "plec_result_svm['Pose'] = pose\n",
    "\n",
    "plec_result_svm.to_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/hard_test/results/SVM/SVM_no-tuning_03.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4648edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the SVM model on the training molecules:\n",
    "svm_plec = SVC(degree = 3, kernel = \"rbf\", probability = True)\n",
    "svm_plec.fit(d_train_csv, Train_Class)\n",
    "\n",
    "#Test the SVM model on the test molecules:\n",
    "prediction_test_svm_plec_class = svm_plec.predict(d_test_csv)\n",
    "prediction_test_svm_plec_prob = svm_plec.predict_proba(d_test_csv)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_svm  = pd.DataFrame({\"Good_Pose_Prob\": prediction_test_svm_plec_prob[:, 1],\n",
    "                                 \"Predicted_Class\": prediction_test_svm_plec_class,\n",
    "                                 \"Real_Class\": Test_Class})\n",
    "\n",
    "rmsd = test_data.iloc[:, 1]\n",
    "pose = test_data.iloc[:, 0]\n",
    "\n",
    "plec_result_svm['RMSD'] = rmsd\n",
    "plec_result_svm['Pose'] = pose\n",
    "\n",
    "plec_result_svm.to_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/hard_test/results/SVM/SVM_no-tuning_04.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3027209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the SVM model on the training molecules:\n",
    "svm_plec = SVC(degree = 3, kernel = \"rbf\", probability = True)\n",
    "svm_plec.fit(d_train_csv, Train_Class)\n",
    "\n",
    "#Test the SVM model on the test molecules:\n",
    "prediction_test_svm_plec_class = svm_plec.predict(d_test_csv)\n",
    "prediction_test_svm_plec_prob = svm_plec.predict_proba(d_test_csv)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_svm  = pd.DataFrame({\"Good_Pose_Prob\": prediction_test_svm_plec_prob[:, 1],\n",
    "                                 \"Predicted_Class\": prediction_test_svm_plec_class,\n",
    "                                 \"Real_Class\": Test_Class})\n",
    "\n",
    "rmsd = test_data.iloc[:, 1]\n",
    "pose = test_data.iloc[:, 0]\n",
    "\n",
    "plec_result_svm['RMSD'] = rmsd\n",
    "plec_result_svm['Pose'] = pose\n",
    "\n",
    "plec_result_svm.to_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/hard_test/results/SVM/SVM_no-tuning_05.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dafcbfa",
   "metadata": {},
   "source": [
    "## ANN models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeb2b08",
   "metadata": {},
   "source": [
    "#### Without hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d2bcfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the ANN model on the training molecules:\n",
    "ann_plec = MLPClassifier(max_iter = 9000)\n",
    "ann_plec.fit(d_train_csv, Train_Class)\n",
    "\n",
    "#Test the ANN model on the test molecules:\n",
    "prediction_test_ann_plec_class = ann_plec.predict(d_test_csv)\n",
    "prediction_test_ann_plec_prob = ann_plec.predict_proba(d_test_csv)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_ann = pd.DataFrame({\"Good_Pose_Prob\": prediction_test_ann_plec_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_ann_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "\n",
    "rmsd = test_data.iloc[:, 1]\n",
    "pose = test_data.iloc[:, 0]\n",
    "\n",
    "plec_result_ann['RMSD'] = rmsd\n",
    "plec_result_ann['Pose'] = pose\n",
    "\n",
    "plec_result_ann.to_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/hard_test/results/ANN/ANN_no-tuning_01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cf00042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the ANN model on the training molecules:\n",
    "ann_plec = MLPClassifier(max_iter = 9000)\n",
    "ann_plec.fit(d_train_csv, Train_Class)\n",
    "\n",
    "#Test the ANN model on the test molecules:\n",
    "prediction_test_ann_plec_class = ann_plec.predict(d_test_csv)\n",
    "prediction_test_ann_plec_prob = ann_plec.predict_proba(d_test_csv)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_ann = pd.DataFrame({\"Good_Pose_Prob\": prediction_test_ann_plec_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_ann_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "\n",
    "rmsd = test_data.iloc[:, 1]\n",
    "pose = test_data.iloc[:, 0]\n",
    "\n",
    "plec_result_ann['RMSD'] = rmsd\n",
    "plec_result_ann['Pose'] = pose\n",
    "\n",
    "plec_result_ann.to_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/hard_test/results/ANN/ANN_no-tuning_02.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b064e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the ANN model on the training molecules:\n",
    "ann_plec = MLPClassifier(max_iter = 9000)\n",
    "ann_plec.fit(d_train_csv, Train_Class)\n",
    "\n",
    "#Test the ANN model on the test molecules:\n",
    "prediction_test_ann_plec_class = ann_plec.predict(d_test_csv)\n",
    "prediction_test_ann_plec_prob = ann_plec.predict_proba(d_test_csv)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_ann = pd.DataFrame({\"Good_Pose_Prob\": prediction_test_ann_plec_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_ann_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "\n",
    "rmsd = test_data.iloc[:, 1]\n",
    "pose = test_data.iloc[:, 0]\n",
    "\n",
    "plec_result_ann['RMSD'] = rmsd\n",
    "plec_result_ann['Pose'] = pose\n",
    "\n",
    "plec_result_ann.to_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/hard_test/results/ANN/ANN_no-tuning_03.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6de7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the ANN model on the training molecules:\n",
    "ann_plec = MLPClassifier(max_iter = 9000)\n",
    "ann_plec.fit(d_train_csv, Train_Class)\n",
    "\n",
    "#Test the ANN model on the test molecules:\n",
    "prediction_test_ann_plec_class = ann_plec.predict(d_test_csv)\n",
    "prediction_test_ann_plec_prob = ann_plec.predict_proba(d_test_csv)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_ann = pd.DataFrame({\"Good_Pose_Prob\": prediction_test_ann_plec_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_ann_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "\n",
    "rmsd = test_data.iloc[:, 1]\n",
    "pose = test_data.iloc[:, 0]\n",
    "\n",
    "plec_result_ann['RMSD'] = rmsd\n",
    "plec_result_ann['Pose'] = pose\n",
    "\n",
    "plec_result_ann.to_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/hard_test/results/ANN/ANN_no-tuning_04.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c84a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the ANN model on the training molecules:\n",
    "ann_plec = MLPClassifier(max_iter = 9000)\n",
    "ann_plec.fit(d_train_csv, Train_Class)\n",
    "\n",
    "#Test the ANN model on the test molecules:\n",
    "prediction_test_ann_plec_class = ann_plec.predict(d_test_csv)\n",
    "prediction_test_ann_plec_prob = ann_plec.predict_proba(d_test_csv)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_ann = pd.DataFrame({\"Good_Pose_Prob\": prediction_test_ann_plec_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_ann_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "\n",
    "rmsd = test_data.iloc[:, 1]\n",
    "pose = test_data.iloc[:, 0]\n",
    "\n",
    "plec_result_ann['RMSD'] = rmsd\n",
    "plec_result_ann['Pose'] = pose\n",
    "\n",
    "plec_result_ann.to_csv(\"/home/vktrannguyen/Projects/redocked/PLEC/hard_test/results/ANN/ANN_no-tuning_05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc6a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
